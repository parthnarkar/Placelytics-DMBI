#!/usr/bin/env python3
"""
Quick Prediction Accuracy Test
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder

# Load and process data
print("ðŸ”„ Loading data...")
df = pd.read_csv('../../data/placementdata.csv')

# Preprocessing
df_processed = df.copy()
label_encoder = LabelEncoder()
df_processed['PlacementStatus_encoded'] = label_encoder.fit_transform(df_processed['PlacementStatus'])

# Feature Engineering
df_processed['Academic_Index'] = (df_processed['CGPA'] * 0.4 + 
                                 df_processed['SSC_Marks']/100 * 0.3 + 
                                 df_processed['HSC_Marks']/100 * 0.3)

df_processed['Experience_Score'] = (df_processed['Internships'] * 2 + 
                                   df_processed['Projects'] + 
                                   df_processed['Workshops/Certifications'] * 1.5)

df_processed['Competency_Score'] = (df_processed['AptitudeTestScore']/100 * 0.6 + 
                                   df_processed['SoftSkillsRating']/5 * 0.4)

# Features and target
numeric_features = ['CGPA', 'Internships', 'Projects', 'Workshops/Certifications', 
                   'AptitudeTestScore', 'SoftSkillsRating', 'SSC_Marks', 'HSC_Marks',
                   'Academic_Index', 'Experience_Score', 'Competency_Score']

X = df_processed[numeric_features]
y = df_processed['PlacementStatus_encoded']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Train models
print("ðŸ¤– Training models...")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
lr_model = LogisticRegression(random_state=42, max_iter=1000)

rf_model.fit(X_train, y_train)
lr_model.fit(X_train, y_train)

# Evaluate models
rf_pred = rf_model.predict(X_test)
lr_pred = lr_model.predict(X_test)

rf_prob = rf_model.predict_proba(X_test)[:, 1]
lr_prob = lr_model.predict_proba(X_test)[:, 1]

rf_accuracy = accuracy_score(y_test, rf_pred)
lr_accuracy = accuracy_score(y_test, lr_pred)

rf_auc = roc_auc_score(y_test, rf_prob)
lr_auc = roc_auc_score(y_test, lr_prob)

print("\nðŸŽ¯ MODEL PERFORMANCE:")
print("-" * 40)
print(f"Random Forest - Accuracy: {rf_accuracy:.3f}, AUC: {rf_auc:.3f}")
print(f"Logistic Regression - Accuracy: {lr_accuracy:.3f}, AUC: {lr_auc:.3f}")

# Test specific prediction scenarios
print("\nðŸ§ª TESTING PREDICTION SCENARIOS:")
print("-" * 40)

test_cases = [
    {
        'name': 'High Performer',
        'data': [9.2, 3, 4, 3, 92, 4.8, 88, 85, 0, 0, 0],  # Will calculate derived features
        'expected': 'High (>70%)'
    },
    {
        'name': 'Average Student',
        'data': [7.5, 1, 2, 1, 75, 4.0, 70, 72, 0, 0, 0],
        'expected': 'Moderate (40-70%)'
    },
    {
        'name': 'At-Risk Student',
        'data': [6.8, 0, 1, 0, 60, 3.2, 60, 65, 0, 0, 0],
        'expected': 'Low (<40%)'
    }
]

for case in test_cases:
    # Calculate derived features
    cgpa, internships, projects, certifications = case['data'][:4]
    aptitude, soft_skills, ssc_marks, hsc_marks = case['data'][4:8]
    
    academic_index = cgpa * 0.4 + ssc_marks/100 * 0.3 + hsc_marks/100 * 0.3
    experience_score = internships * 2 + projects + certifications * 1.5
    competency_score = aptitude/100 * 0.6 + soft_skills/5 * 0.4
    
    # Update data with derived features
    case['data'][8] = academic_index
    case['data'][9] = experience_score
    case['data'][10] = competency_score
    
    # Make predictions
    student_data = np.array([case['data']])
    rf_prob_pred = rf_model.predict_proba(student_data)[0][1]
    lr_prob_pred = lr_model.predict_proba(student_data)[0][1]
    ensemble_prob = (rf_prob_pred * 0.6 + lr_prob_pred * 0.4)
    
    print(f"\n{case['name']}:")
    print(f"  Expected: {case['expected']}")
    print(f"  RF Prediction: {rf_prob_pred:.1%}")
    print(f"  LR Prediction: {lr_prob_pred:.1%}")
    print(f"  Ensemble: {ensemble_prob:.1%}")
    
    # Validate prediction reasonableness
    if case['expected'].startswith('High') and ensemble_prob > 0.7:
        print("  âœ… Prediction matches expectation")
    elif case['expected'].startswith('Moderate') and 0.4 <= ensemble_prob <= 0.7:
        print("  âœ… Prediction matches expectation")
    elif case['expected'].startswith('Low') and ensemble_prob < 0.4:
        print("  âœ… Prediction matches expectation")
    else:
        print("  âš ï¸ Prediction needs review")

# Calculate overall placement rate for context
overall_rate = (df['PlacementStatus'] == 'Placed').mean()
print(f"\nðŸ“Š Dataset overall placement rate: {overall_rate:.1%}")

print("\nâœ… Quick validation complete!")
print("ðŸŽ¯ Models show good performance and realistic predictions!")