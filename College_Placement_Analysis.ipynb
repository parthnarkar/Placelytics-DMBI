{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f282920e",
   "metadata": {},
   "source": [
    "# üöÄ College Placement Data Analysis & Prediction\n",
    "\n",
    "## üìä Domain: Education Analytics\n",
    "\n",
    "### üéØ Objective: \n",
    "Analyze student placement data and build a machine learning model to predict whether a student will be placed or not, based on academic and skill-related features.\n",
    "\n",
    "### üìã Project Overview:\n",
    "- **Dataset**: `placementdata.csv`\n",
    "- **Target**: Predict placement status (Placed/Not Placed)\n",
    "- **Approach**: Multiple ML algorithms with comprehensive evaluation\n",
    "- **Business Goal**: Identify key factors that influence student placement success\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a35f4",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Required Libraries\n",
    "\n",
    "Let's start by importing all the necessary libraries for data manipulation, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c049768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Model evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö All libraries imported successfully!\")\n",
    "print(\"üéØ Ready to start the placement prediction analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d0730",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load and Explore Dataset\n",
    "\n",
    "Now let's load the placement data and explore its structure to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('placementdata.csv')\n",
    "\n",
    "print(\"üìä Dataset loaded successfully!\")\n",
    "print(f\"üìê Dataset shape: {df.shape}\")\n",
    "print(f\"üìù Features: {df.shape[1] - 1}\")\n",
    "print(f\"üë• Students: {df.shape[0]}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"üîç First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Display dataset information\n",
    "print(\"‚ÑπÔ∏è Dataset Information:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"üìà Basic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d364f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç Missing Values Analysis:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "if missing_df['Missing Count'].sum() == 0:\n",
    "    print(\"‚úÖ Great! No missing values found in the dataset.\")\n",
    "    \n",
    "# Check unique values in categorical columns\n",
    "print(\"\\nüè∑Ô∏è Unique values in categorical columns:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n",
    "    \n",
    "# Check target variable distribution\n",
    "print(f\"\\nüéØ Target Variable Distribution:\")\n",
    "print(df['PlacementStatus'].value_counts())\n",
    "print(f\"\\nPlacement Rate: {(df['PlacementStatus'] == 'Placed').mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecee1ea",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Data Preprocessing\n",
    "\n",
    "Time to clean and prepare our data for machine learning models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original dataset for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# 1. Encode the target variable (PlacementStatus)\n",
    "print(\"üéØ Encoding target variable...\")\n",
    "label_encoder_target = LabelEncoder()\n",
    "df_processed['PlacementStatus_encoded'] = label_encoder_target.fit_transform(df_processed['PlacementStatus'])\n",
    "\n",
    "# Check the encoding\n",
    "print(\"Target encoding mapping:\")\n",
    "for i, class_name in enumerate(label_encoder_target.classes_):\n",
    "    print(f\"  {class_name} -> {i}\")\n",
    "\n",
    "# 2. Encode categorical variables\n",
    "print(\"\\nüè∑Ô∏è Encoding categorical variables...\")\n",
    "label_encoders = {}\n",
    "\n",
    "# ExtracurricularActivities: Yes/No\n",
    "df_processed['ExtracurricularActivities_encoded'] = label_encoder_target.fit_transform(df_processed['ExtracurricularActivities'])\n",
    "\n",
    "# PlacementTraining: Yes/No  \n",
    "df_processed['PlacementTraining_encoded'] = label_encoder_target.fit_transform(df_processed['PlacementTraining'])\n",
    "\n",
    "print(\"‚úÖ Categorical variables encoded successfully!\")\n",
    "\n",
    "# 3. Create a clean dataset with only numeric features\n",
    "numeric_features = ['CGPA', 'Internships', 'Projects', 'Workshops/Certifications', \n",
    "                   'AptitudeTestScore', 'SoftSkillsRating', 'SSC_Marks', 'HSC_Marks',\n",
    "                   'ExtracurricularActivities_encoded', 'PlacementTraining_encoded']\n",
    "\n",
    "df_clean = df_processed[numeric_features + ['PlacementStatus_encoded']].copy()\n",
    "\n",
    "print(f\"\\nüìä Clean dataset shape: {df_clean.shape}\")\n",
    "print(f\"üî¢ Numeric features: {len(numeric_features)}\")\n",
    "\n",
    "# Display the processed dataset\n",
    "print(\"\\nüîç First 5 rows of processed dataset:\")\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd455613",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's dive deep into understanding our data through visualizations and statistical analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03836a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plotting environment\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Count plot for Placement Status\n",
    "plt.subplot(2, 3, 1)\n",
    "placement_counts = df['PlacementStatus'].value_counts()\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "plt.pie(placement_counts.values, labels=placement_counts.index, autopct='%1.1f%%', \n",
    "        colors=colors, startangle=90)\n",
    "plt.title('üìä Placement Status Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. CGPA vs Placement Status\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.boxplot(data=df, x='PlacementStatus', y='CGPA', palette=['#FF6B6B', '#4ECDC4'])\n",
    "plt.title('üìö CGPA vs Placement Status', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('CGPA')\n",
    "\n",
    "# 3. Internships vs Placement Status\n",
    "plt.subplot(2, 3, 3)\n",
    "internship_placement = pd.crosstab(df['Internships'], df['PlacementStatus'], normalize='index') * 100\n",
    "internship_placement.plot(kind='bar', color=['#FF6B6B', '#4ECDC4'])\n",
    "plt.title('üíº Internships vs Placement Rate', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Internships')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.legend(title='Placement Status')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# 4. Workshops/Certifications vs Placement Status\n",
    "plt.subplot(2, 3, 4)\n",
    "cert_placement = pd.crosstab(df['Workshops/Certifications'], df['PlacementStatus'], normalize='index') * 100\n",
    "cert_placement.plot(kind='bar', color=['#FF6B6B', '#4ECDC4'])\n",
    "plt.title('üèÜ Certifications vs Placement Rate', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Workshops/Certifications')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.legend(title='Placement Status')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# 5. Aptitude Test Score vs Placement Status\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.boxplot(data=df, x='PlacementStatus', y='AptitudeTestScore', palette=['#FF6B6B', '#4ECDC4'])\n",
    "plt.title('üß† Aptitude Test Score vs Placement', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Aptitude Test Score')\n",
    "\n",
    "# 6. Soft Skills Rating vs Placement Status\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.boxplot(data=df, x='PlacementStatus', y='SoftSkillsRating', palette=['#FF6B6B', '#4ECDC4'])\n",
    "plt.title('üó£Ô∏è Soft Skills vs Placement', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Soft Skills Rating')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some key statistics\n",
    "print(\"üìà Key Statistics:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "placed_students = df[df['PlacementStatus'] == 'Placed']\n",
    "not_placed_students = df[df['PlacementStatus'] == 'NotPlaced']\n",
    "\n",
    "print(f\"üìä Average CGPA - Placed: {placed_students['CGPA'].mean():.2f}, Not Placed: {not_placed_students['CGPA'].mean():.2f}\")\n",
    "print(f\"üíº Average Internships - Placed: {placed_students['Internships'].mean():.2f}, Not Placed: {not_placed_students['Internships'].mean():.2f}\")\n",
    "print(f\"üèÜ Average Certifications - Placed: {placed_students['Workshops/Certifications'].mean():.2f}, Not Placed: {not_placed_students['Workshops/Certifications'].mean():.2f}\")\n",
    "print(f\"üß† Average Aptitude Score - Placed: {placed_students['AptitudeTestScore'].mean():.2f}, Not Placed: {not_placed_students['AptitudeTestScore'].mean():.2f}\")\n",
    "print(f\"üó£Ô∏è Average Soft Skills - Placed: {placed_students['SoftSkillsRating'].mean():.2f}, Not Placed: {not_placed_students['SoftSkillsRating'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f53ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create correlation matrix for numeric features\n",
    "correlation_matrix = df_clean.corr()\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('üî• Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze correlations with placement status\n",
    "print(\"üéØ Correlation with Placement Status:\")\n",
    "print(\"=\"*50)\n",
    "placement_correlations = correlation_matrix['PlacementStatus_encoded'].sort_values(ascending=False)\n",
    "\n",
    "for feature, correlation in placement_correlations.items():\n",
    "    if feature != 'PlacementStatus_encoded':\n",
    "        direction = \"üìà Positive\" if correlation > 0 else \"üìâ Negative\"\n",
    "        strength = \"Strong\" if abs(correlation) > 0.5 else \"Moderate\" if abs(correlation) > 0.3 else \"Weak\"\n",
    "        print(f\"{feature}: {correlation:.3f} ({direction}, {strength})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd9ff04",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Data Splitting\n",
    "\n",
    "Now let's prepare our data for machine learning by splitting it into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = df_clean[numeric_features]  # All numeric features\n",
    "y = df_clean['PlacementStatus_encoded']  # Target variable\n",
    "\n",
    "print(\"üéØ Feature and Target Selection:\")\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"\\nFeatures included: {list(X.columns)}\")\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Split Summary:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Check class distribution in train and test sets\n",
    "print(f\"\\nüìà Class Distribution:\")\n",
    "print(\"Training set:\")\n",
    "train_dist = pd.Series(y_train).value_counts(normalize=True) * 100\n",
    "for class_val, percentage in train_dist.items():\n",
    "    class_name = \"Placed\" if class_val == 1 else \"NotPlaced\"\n",
    "    print(f\"  {class_name}: {percentage:.1f}%\")\n",
    "\n",
    "print(\"Testing set:\")\n",
    "test_dist = pd.Series(y_test).value_counts(normalize=True) * 100\n",
    "for class_val, percentage in test_dist.items():\n",
    "    class_name = \"Placed\" if class_val == 1 else \"NotPlaced\"\n",
    "    print(f\"  {class_name}: {percentage:.1f}%\")\n",
    "\n",
    "# Feature Scaling (optional but recommended for some algorithms)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Data preprocessing completed!\")\n",
    "print(f\"üìè Features have been standardized for better model performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c901c20a",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Machine Learning Model Implementation\n",
    "\n",
    "Time to build and train multiple machine learning models to predict student placement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Dictionary to store trained models and predictions\n",
    "trained_models = {}\n",
    "predictions = {}\n",
    "\n",
    "print(\"üöÄ Training Multiple Machine Learning Models...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train each model and make predictions\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nüîÑ Training {model_name}...\")\n",
    "    \n",
    "    # Use scaled data for KNN and Logistic Regression, original data for tree-based models\n",
    "    if model_name in ['K-Nearest Neighbors', 'Logistic Regression']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Store the trained model and predictions\n",
    "    trained_models[model_name] = model\n",
    "    predictions[model_name] = y_pred\n",
    "    \n",
    "    print(f\"‚úÖ {model_name} training completed!\")\n",
    "\n",
    "print(f\"\\nüéâ All models trained successfully!\")\n",
    "print(f\"üìä Ready for evaluation and comparison!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f9443",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Model Evaluation and Comparison\n",
    "\n",
    "Let's evaluate all our models using multiple metrics and compare their performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for all models\n",
    "evaluation_results = []\n",
    "\n",
    "print(\"üìä Model Performance Evaluation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    evaluation_results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nü§ñ {model_name}:\")\n",
    "    print(f\"   Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"   Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"   Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"   F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "\n",
    "# Create a comprehensive results DataFrame\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "print(f\"\\nüìã Complete Model Comparison Table:\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Sort by accuracy to find the best model\n",
    "results_df_sorted = results_df.sort_values('Accuracy', ascending=False)\n",
    "best_model_name = results_df_sorted.iloc[0]['Model']\n",
    "best_accuracy = results_df_sorted.iloc[0]['Accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ Best Performing Model: {best_model_name}\")\n",
    "print(f\"üéØ Best Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrices for all models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Create confusion matrix display\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                display_labels=['Not Placed', 'Placed'])\n",
    "    disp.plot(ax=axes[idx], cmap='Blues', values_format='d')\n",
    "    axes[idx].set_title(f'{model_name}\\nAccuracy: {accuracy_score(y_test, y_pred):.3f}', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('üéØ Confusion Matrices for All Models', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Model Performance Comparison Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create subplots for different metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    plt.subplot(2, 2, idx+1)\n",
    "    \n",
    "    # Sort models by the current metric\n",
    "    metric_data = results_df.sort_values(metric, ascending=True)\n",
    "    \n",
    "    bars = plt.barh(metric_data['Model'], metric_data[metric], color=colors[idx], alpha=0.8)\n",
    "    plt.title(f'üìä {metric} Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(f'{metric} Score')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.3f}', ha='left', va='center', fontweight='bold')\n",
    "    \n",
    "    plt.xlim(0, 1.1)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcaab62",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Best Model Selection\n",
    "\n",
    "Based on our evaluation metrics, let's select and analyze the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64256038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model based on F1-score (balanced metric)\n",
    "best_model_f1 = results_df.loc[results_df['F1-Score'].idxmax()]\n",
    "best_model_accuracy = results_df.loc[results_df['Accuracy'].idxmax()]\n",
    "\n",
    "print(\"üèÜ Best Model Selection Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Best by Accuracy: {best_model_accuracy['Model']}\")\n",
    "print(f\"   Accuracy: {best_model_accuracy['Accuracy']:.4f} ({best_model_accuracy['Accuracy']*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Best by F1-Score: {best_model_f1['Model']}\")\n",
    "print(f\"   F1-Score: {best_model_f1['F1-Score']:.4f} ({best_model_f1['F1-Score']*100:.2f}%)\")\n",
    "\n",
    "# Select the model with highest F1-score for final analysis\n",
    "final_model_name = best_model_f1['Model']\n",
    "final_model = trained_models[final_model_name]\n",
    "\n",
    "print(f\"\\nüéØ Selected Model: {final_model_name}\")\n",
    "print(f\"üìà Justification: F1-Score provides a balanced measure of precision and recall\")\n",
    "\n",
    "# Detailed classification report for the best model\n",
    "print(f\"\\nüìã Detailed Classification Report - {final_model_name}:\")\n",
    "print(\"=\"*60)\n",
    "y_pred_final = predictions[final_model_name]\n",
    "print(classification_report(y_test, y_pred_final, \n",
    "                          target_names=['Not Placed', 'Placed'],\n",
    "                          digits=4))\n",
    "\n",
    "# Store the best model for future predictions\n",
    "best_model = final_model\n",
    "best_model_name_final = final_model_name\n",
    "\n",
    "print(f\"‚úÖ Best model ({best_model_name_final}) selected and ready for predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c961b6fc",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features contribute most to placement predictions, especially using Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest model\n",
    "rf_model = trained_models['Random Forest']\n",
    "feature_importance = rf_model.feature_importances_\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': numeric_features,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"üîç Feature Importance Analysis - Random Forest\")\n",
    "print(\"=\"*60)\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create horizontal bar plot\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))\n",
    "bars = plt.barh(range(len(importance_df)), importance_df['Importance'], color=colors)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Feature Importance', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
    "plt.title('üåü Feature Importance - Random Forest Model', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Add feature names to y-axis\n",
    "plt.yticks(range(len(importance_df)), importance_df['Feature'])\n",
    "\n",
    "# Add value labels on bars\n",
    "for idx, (bar, importance) in enumerate(zip(bars, importance_df['Importance'])):\n",
    "    plt.text(importance + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "             f'{importance:.3f}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze top features\n",
    "print(f\"\\nüèÜ Top 5 Most Important Features:\")\n",
    "print(\"=\"*40)\n",
    "for idx, (_, row) in enumerate(importance_df.head().iterrows(), 1):\n",
    "    percentage = row['Importance'] * 100\n",
    "    print(f\"{idx}. {row['Feature']}: {row['Importance']:.4f} ({percentage:.2f}%)\")\n",
    "\n",
    "# Feature importance insights\n",
    "print(f\"\\nüí° Key Insights:\")\n",
    "print(\"=\"*40)\n",
    "top_feature = importance_df.iloc[0]\n",
    "print(f\"ü•á Most Important: {top_feature['Feature']} ({top_feature['Importance']:.3f})\")\n",
    "\n",
    "if 'CGPA' in importance_df['Feature'].values:\n",
    "    cgpa_importance = importance_df[importance_df['Feature'] == 'CGPA']['Importance'].iloc[0]\n",
    "    cgpa_rank = importance_df[importance_df['Feature'] == 'CGPA'].index[0] + 1\n",
    "    print(f\"üìö CGPA ranks #{cgpa_rank} with importance: {cgpa_importance:.3f}\")\n",
    "\n",
    "if 'Internships' in importance_df['Feature'].values:\n",
    "    intern_importance = importance_df[importance_df['Feature'] == 'Internships']['Importance'].iloc[0]\n",
    "    intern_rank = importance_df[importance_df['Feature'] == 'Internships'].index[0] + 1\n",
    "    print(f\"üíº Internships rank #{intern_rank} with importance: {intern_importance:.3f}\")\n",
    "\n",
    "# Calculate cumulative importance\n",
    "importance_df['Cumulative_Importance'] = importance_df['Importance'].cumsum()\n",
    "top_3_cumulative = importance_df.head(3)['Cumulative_Importance'].iloc[-1]\n",
    "print(f\"üìä Top 3 features explain {top_3_cumulative:.1%} of the model's decisions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4771e",
   "metadata": {},
   "source": [
    "## üîü New Student Placement Prediction\n",
    "\n",
    "Let's create a prediction system for new students entering the placement process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a42e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to predict placement for new students\n",
    "def predict_placement(cgpa, internships, projects, certifications, aptitude_score, \n",
    "                     soft_skills, ssc_marks, hsc_marks, extracurricular, placement_training):\n",
    "    \"\"\"\n",
    "    Predict placement probability for a new student\n",
    "    \"\"\"\n",
    "    # Encode categorical variables\n",
    "    extracurricular_encoded = 1 if extracurricular.lower() == 'yes' else 0\n",
    "    placement_training_encoded = 1 if placement_training.lower() == 'yes' else 0\n",
    "    \n",
    "    # Create feature array in the same order as training data\n",
    "    new_student = np.array([[cgpa, internships, projects, certifications, aptitude_score,\n",
    "                            soft_skills, ssc_marks, hsc_marks, extracurricular_encoded, \n",
    "                            placement_training_encoded]])\n",
    "    \n",
    "    # Use the best model for prediction\n",
    "    if best_model_name_final in ['K-Nearest Neighbors', 'Logistic Regression']:\n",
    "        # Scale the features for models that require scaling\n",
    "        new_student_scaled = scaler.transform(new_student)\n",
    "        prediction = best_model.predict(new_student_scaled)[0]\n",
    "        probability = best_model.predict_proba(new_student_scaled)[0]\n",
    "    else:\n",
    "        prediction = best_model.predict(new_student)[0]\n",
    "        probability = best_model.predict_proba(new_student)[0]\n",
    "    \n",
    "    return prediction, probability\n",
    "\n",
    "# Example predictions for different student profiles\n",
    "print(\"üéì Placement Predictions for New Students\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Example 1: High-performing student\n",
    "print(\"\\nüë®‚Äçüéì Student Profile 1: High Performer\")\n",
    "print(\"-\" * 40)\n",
    "student1_details = {\n",
    "    'cgpa': 8.5, 'internships': 2, 'projects': 3, 'certifications': 3,\n",
    "    'aptitude_score': 90, 'soft_skills': 4.5, 'ssc_marks': 85, 'hsc_marks': 88,\n",
    "    'extracurricular': 'Yes', 'placement_training': 'Yes'\n",
    "}\n",
    "\n",
    "prediction1, prob1 = predict_placement(**student1_details)\n",
    "result1 = \"PLACED\" if prediction1 == 1 else \"NOT PLACED\"\n",
    "confidence1 = prob1[1] if prediction1 == 1 else prob1[0]\n",
    "\n",
    "print(f\"üìä Profile: CGPA: {student1_details['cgpa']}, Internships: {student1_details['internships']}, Projects: {student1_details['projects']}\")\n",
    "print(f\"üß† Aptitude: {student1_details['aptitude_score']}, Soft Skills: {student1_details['soft_skills']}\")\n",
    "print(f\"üéØ Prediction: {result1} (Confidence: {confidence1:.2%})\")\n",
    "\n",
    "# Example 2: Average student\n",
    "print(\"\\nüë©‚Äçüéì Student Profile 2: Average Performer\")\n",
    "print(\"-\" * 40)\n",
    "student2_details = {\n",
    "    'cgpa': 7.2, 'internships': 1, 'projects': 2, 'certifications': 1,\n",
    "    'aptitude_score': 75, 'soft_skills': 4.0, 'ssc_marks': 70, 'hsc_marks': 72,\n",
    "    'extracurricular': 'No', 'placement_training': 'Yes'\n",
    "}\n",
    "\n",
    "prediction2, prob2 = predict_placement(**student2_details)\n",
    "result2 = \"PLACED\" if prediction2 == 1 else \"NOT PLACED\"\n",
    "confidence2 = prob2[1] if prediction2 == 1 else prob2[0]\n",
    "\n",
    "print(f\"üìä Profile: CGPA: {student2_details['cgpa']}, Internships: {student2_details['internships']}, Projects: {student2_details['projects']}\")\n",
    "print(f\"üß† Aptitude: {student2_details['aptitude_score']}, Soft Skills: {student2_details['soft_skills']}\")\n",
    "print(f\"üéØ Prediction: {result2} (Confidence: {confidence2:.2%})\")\n",
    "\n",
    "# Example 3: Below-average student\n",
    "print(\"\\nüë®‚Äçüéì Student Profile 3: Below Average Performer\")\n",
    "print(\"-\" * 40)\n",
    "student3_details = {\n",
    "    'cgpa': 6.8, 'internships': 0, 'projects': 1, 'certifications': 0,\n",
    "    'aptitude_score': 65, 'soft_skills': 3.5, 'ssc_marks': 60, 'hsc_marks': 65,\n",
    "    'extracurricular': 'No', 'placement_training': 'No'\n",
    "}\n",
    "\n",
    "prediction3, prob3 = predict_placement(**student3_details)\n",
    "result3 = \"PLACED\" if prediction3 == 1 else \"NOT PLACED\"\n",
    "confidence3 = prob3[1] if prediction3 == 1 else prob3[0]\n",
    "\n",
    "print(f\"üìä Profile: CGPA: {student3_details['cgpa']}, Internships: {student3_details['internships']}, Projects: {student3_details['projects']}\")\n",
    "print(f\"üß† Aptitude: {student3_details['aptitude_score']}, Soft Skills: {student3_details['soft_skills']}\")\n",
    "print(f\"üéØ Prediction: {result3} (Confidence: {confidence3:.2%})\")\n",
    "\n",
    "# Interactive prediction function\n",
    "print(f\"\\nüîÆ The prediction system is ready!\")\n",
    "print(f\"ü§ñ Model Used: {best_model_name_final}\")\n",
    "print(f\"üìà Model Accuracy: {results_df[results_df['Model'] == best_model_name_final]['Accuracy'].iloc[0]:.2%}\")\n",
    "print(f\"‚úÖ You can now use the predict_placement() function for any new student!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36892ead",
   "metadata": {},
   "source": [
    "## üß© Business Analytics Insights\n",
    "\n",
    "Let's extract actionable business insights from our analysis to help improve placement rates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive business insights\n",
    "print(\"üíº BUSINESS ANALYTICS INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. CGPA Analysis\n",
    "placed_cgpa = df[df['PlacementStatus'] == 'Placed']['CGPA'].mean()\n",
    "not_placed_cgpa = df[df['PlacementStatus'] == 'NotPlaced']['CGPA'].mean()\n",
    "cgpa_diff = placed_cgpa - not_placed_cgpa\n",
    "\n",
    "print(f\"\\nüìö CGPA INSIGHTS:\")\n",
    "print(f\"   ‚Ä¢ Average CGPA of placed students: {placed_cgpa:.2f}\")\n",
    "print(f\"   ‚Ä¢ Average CGPA of not placed students: {not_placed_cgpa:.2f}\")\n",
    "print(f\"   ‚Ä¢ CGPA difference: {cgpa_diff:.2f} points higher for placed students\")\n",
    "\n",
    "# CGPA threshold analysis\n",
    "high_cgpa_threshold = 8.0\n",
    "high_cgpa_placed = len(df[(df['CGPA'] >= high_cgpa_threshold) & (df['PlacementStatus'] == 'Placed')])\n",
    "high_cgpa_total = len(df[df['CGPA'] >= high_cgpa_threshold])\n",
    "high_cgpa_rate = (high_cgpa_placed / high_cgpa_total) * 100 if high_cgpa_total > 0 else 0\n",
    "\n",
    "low_cgpa_placed = len(df[(df['CGPA'] < high_cgpa_threshold) & (df['PlacementStatus'] == 'Placed')])\n",
    "low_cgpa_total = len(df[df['CGPA'] < high_cgpa_threshold])\n",
    "low_cgpa_rate = (low_cgpa_placed / low_cgpa_total) * 100 if low_cgpa_total > 0 else 0\n",
    "\n",
    "print(f\"   ‚Ä¢ Placement rate for CGPA ‚â• {high_cgpa_threshold}: {high_cgpa_rate:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Placement rate for CGPA < {high_cgpa_threshold}: {low_cgpa_rate:.1f}%\")\n",
    "\n",
    "# 2. Internship Analysis\n",
    "print(f\"\\nüíº INTERNSHIP INSIGHTS:\")\n",
    "internship_analysis = df.groupby('Internships')['PlacementStatus'].apply(lambda x: (x == 'Placed').mean() * 100)\n",
    "for internships, rate in internship_analysis.items():\n",
    "    print(f\"   ‚Ä¢ {internships} internships: {rate:.1f}% placement rate\")\n",
    "\n",
    "# Students with vs without internships\n",
    "with_internships = df[df['Internships'] > 0]['PlacementStatus']\n",
    "without_internships = df[df['Internships'] == 0]['PlacementStatus']\n",
    "\n",
    "with_internship_rate = (with_internships == 'Placed').mean() * 100\n",
    "without_internship_rate = (without_internships == 'Placed').mean() * 100\n",
    "internship_multiplier = with_internship_rate / without_internship_rate if without_internship_rate > 0 else 0\n",
    "\n",
    "print(f\"   ‚Ä¢ With internships: {with_internship_rate:.1f}% placement rate\")\n",
    "print(f\"   ‚Ä¢ Without internships: {without_internship_rate:.1f}% placement rate\")\n",
    "print(f\"   ‚Ä¢ Internships increase placement chances by {internship_multiplier:.1f}x\")\n",
    "\n",
    "# 3. Certification Analysis\n",
    "print(f\"\\nüèÜ CERTIFICATION INSIGHTS:\")\n",
    "cert_analysis = df.groupby('Workshops/Certifications')['PlacementStatus'].apply(lambda x: (x == 'Placed').mean() * 100)\n",
    "for certs, rate in cert_analysis.items():\n",
    "    print(f\"   ‚Ä¢ {certs} certifications: {rate:.1f}% placement rate\")\n",
    "\n",
    "# 4. Aptitude Score Analysis\n",
    "print(f\"\\nüß† APTITUDE SCORE INSIGHTS:\")\n",
    "aptitude_threshold = 80\n",
    "high_aptitude_rate = len(df[(df['AptitudeTestScore'] >= aptitude_threshold) & (df['PlacementStatus'] == 'Placed')]) / len(df[df['AptitudeTestScore'] >= aptitude_threshold]) * 100\n",
    "low_aptitude_rate = len(df[(df['AptitudeTestScore'] < aptitude_threshold) & (df['PlacementStatus'] == 'Placed')]) / len(df[df['AptitudeTestScore'] < aptitude_threshold]) * 100\n",
    "\n",
    "print(f\"   ‚Ä¢ High aptitude (‚â•{aptitude_threshold}): {high_aptitude_rate:.1f}% placement rate\")\n",
    "print(f\"   ‚Ä¢ Low aptitude (<{aptitude_threshold}): {low_aptitude_rate:.1f}% placement rate\")\n",
    "\n",
    "# 5. Soft Skills Analysis\n",
    "print(f\"\\nüó£Ô∏è SOFT SKILLS INSIGHTS:\")\n",
    "soft_skills_threshold = 4.0\n",
    "high_soft_skills = df[df['SoftSkillsRating'] >= soft_skills_threshold]\n",
    "low_soft_skills = df[df['SoftSkillsRating'] < soft_skills_threshold]\n",
    "\n",
    "high_soft_rate = (high_soft_skills['PlacementStatus'] == 'Placed').mean() * 100\n",
    "low_soft_rate = (low_soft_skills['PlacementStatus'] == 'Placed').mean() * 100\n",
    "\n",
    "print(f\"   ‚Ä¢ High soft skills (‚â•{soft_skills_threshold}): {high_soft_rate:.1f}% placement rate\")\n",
    "print(f\"   ‚Ä¢ Low soft skills (<{soft_skills_threshold}): {low_soft_rate:.1f}% placement rate\")\n",
    "\n",
    "# 6. Combined Factors Analysis\n",
    "print(f\"\\nüéØ COMBINED SUCCESS FACTORS:\")\n",
    "success_criteria = (\n",
    "    (df['CGPA'] >= 8.0) & \n",
    "    (df['Internships'] >= 1) & \n",
    "    (df['Workshops/Certifications'] >= 2)\n",
    ")\n",
    "success_students = df[success_criteria]\n",
    "success_rate = (success_students['PlacementStatus'] == 'Placed').mean() * 100\n",
    "\n",
    "print(f\"   ‚Ä¢ Students with CGPA‚â•8.0 + ‚â•1 internship + ‚â•2 certifications:\")\n",
    "print(f\"     Placement rate: {success_rate:.1f}%\")\n",
    "print(f\"     Total students meeting criteria: {len(success_students)}\")\n",
    "\n",
    "# 7. Key Recommendations\n",
    "print(f\"\\nüí° KEY RECOMMENDATIONS:\")\n",
    "print(\"=\"*50)\n",
    "print(\"   1. üéì Maintain CGPA above 8.0 for significantly higher placement chances\")\n",
    "print(f\"   2. üíº Complete at least 1 internship (increases chances by {internship_multiplier:.1f}x)\")\n",
    "print(\"   3. üèÜ Earn 2+ certifications to boost employability\")\n",
    "print(f\"   4. üß† Score above {aptitude_threshold} in aptitude tests\")\n",
    "print(f\"   5. üó£Ô∏è Develop soft skills (target rating ‚â•{soft_skills_threshold})\")\n",
    "print(\"   6. üéØ Focus on placement training programs\")\n",
    "print(\"   7. üèÉ‚Äç‚ôÇÔ∏è Participate in extracurricular activities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8946e5cf",
   "metadata": {},
   "source": [
    "## üìä Results Visualization & Summary\n",
    "\n",
    "Let's create a comprehensive summary of our findings with final visualizations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2911ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# 1. Model Accuracy Comparison\n",
    "models_sorted = results_df.sort_values('Accuracy', ascending=True)\n",
    "colors = ['#FF6B6B' if model != best_model_name_final else '#4ECDC4' for model in models_sorted['Model']]\n",
    "\n",
    "bars1 = ax1.barh(models_sorted['Model'], models_sorted['Accuracy'], color=colors, alpha=0.8)\n",
    "ax1.set_title('üèÜ Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Accuracy Score')\n",
    "ax1.set_xlim(0, 1)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars1, models_sorted['Accuracy']):\n",
    "    ax1.text(acc + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{acc:.3f}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "# 2. Feature Importance (Top 6)\n",
    "top_features = importance_df.head(6)\n",
    "bars2 = ax2.bar(range(len(top_features)), top_features['Importance'], \n",
    "                color='#96CEB4', alpha=0.8)\n",
    "ax2.set_title('üåü Top 6 Feature Importance', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Features')\n",
    "ax2.set_ylabel('Importance Score')\n",
    "ax2.set_xticks(range(len(top_features)))\n",
    "ax2.set_xticklabels(top_features['Feature'], rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar, imp in zip(bars2, top_features['Importance']):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "             f'{imp:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Placement Rate by Key Factors\n",
    "factors = ['Overall', 'CGPA‚â•8.0', '‚â•1 Internship', '‚â•2 Certifications', 'High Aptitude', 'All Combined']\n",
    "rates = [\n",
    "    (df['PlacementStatus'] == 'Placed').mean() * 100,\n",
    "    (df[df['CGPA'] >= 8.0]['PlacementStatus'] == 'Placed').mean() * 100,\n",
    "    (df[df['Internships'] >= 1]['PlacementStatus'] == 'Placed').mean() * 100,\n",
    "    (df[df['Workshops/Certifications'] >= 2]['PlacementStatus'] == 'Placed').mean() * 100,\n",
    "    (df[df['AptitudeTestScore'] >= 80]['PlacementStatus'] == 'Placed').mean() * 100,\n",
    "    success_rate\n",
    "]\n",
    "\n",
    "colors3 = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#FF9FF3']\n",
    "bars3 = ax3.bar(factors, rates, color=colors3, alpha=0.8)\n",
    "ax3.set_title('üìà Placement Rates by Key Factors', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('Placement Rate (%)')\n",
    "ax3.set_ylim(0, 100)\n",
    "plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar, rate in zip(bars3, rates):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Success Profile Visualization\n",
    "success_profile = {\n",
    "    'CGPA': 8.5,\n",
    "    'Internships': 2,\n",
    "    'Certifications': 3,\n",
    "    'Aptitude': 90,\n",
    "    'Soft Skills': 4.5,\n",
    "    'Projects': 3\n",
    "}\n",
    "\n",
    "average_profile = {\n",
    "    'CGPA': df['CGPA'].mean(),\n",
    "    'Internships': df['Internships'].mean(),\n",
    "    'Certifications': df['Workshops/Certifications'].mean(),\n",
    "    'Aptitude': df['AptitudeTestScore'].mean(),\n",
    "    'Soft Skills': df['SoftSkillsRating'].mean(),\n",
    "    'Projects': df['Projects'].mean()\n",
    "}\n",
    "\n",
    "# Normalize values for radar chart effect\n",
    "categories = list(success_profile.keys())\n",
    "success_values = [success_profile[cat] / max(success_profile[cat], average_profile[cat]) for cat in categories]\n",
    "average_values = [average_profile[cat] / max(success_profile[cat], average_profile[cat]) for cat in categories]\n",
    "\n",
    "x_pos = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "ax4.bar(x_pos - width/2, success_values, width, label='Ideal Profile', color='#4ECDC4', alpha=0.8)\n",
    "ax4.bar(x_pos + width/2, average_values, width, label='Average Student', color='#FF6B6B', alpha=0.8)\n",
    "ax4.set_title('üë®‚Äçüéì Ideal vs Average Student Profile', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('Normalized Score')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(categories, rotation=45, ha='right')\n",
    "ax4.legend()\n",
    "ax4.set_ylim(0, 1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final Project Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ COLLEGE PLACEMENT PREDICTION PROJECT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total Students: {len(df):,}\")\n",
    "print(f\"   ‚Ä¢ Features Analyzed: {len(numeric_features)}\")\n",
    "print(f\"   ‚Ä¢ Overall Placement Rate: {(df['PlacementStatus'] == 'Placed').mean():.1%}\")\n",
    "\n",
    "print(f\"\\nü§ñ Machine Learning Results:\")\n",
    "print(f\"   ‚Ä¢ Best Model: {best_model_name_final}\")\n",
    "print(f\"   ‚Ä¢ Model Accuracy: {results_df[results_df['Model'] == best_model_name_final]['Accuracy'].iloc[0]:.1%}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {results_df[results_df['Model'] == best_model_name_final]['F1-Score'].iloc[0]:.3f}\")\n",
    "\n",
    "print(f\"\\nüîç Key Success Factors:\")\n",
    "print(f\"   1. {importance_df.iloc[0]['Feature']}: {importance_df.iloc[0]['Importance']:.3f} importance\")\n",
    "print(f\"   2. {importance_df.iloc[1]['Feature']}: {importance_df.iloc[1]['Importance']:.3f} importance\")\n",
    "print(f\"   3. {importance_df.iloc[2]['Feature']}: {importance_df.iloc[2]['Importance']:.3f} importance\")\n",
    "\n",
    "print(f\"\\nüí° Business Impact:\")\n",
    "print(f\"   ‚Ä¢ High-performing students (CGPA‚â•8.0 + internships + certs): {success_rate:.1f}% placement rate\")\n",
    "print(f\"   ‚Ä¢ Internships increase placement chances by {internship_multiplier:.1f}x\")\n",
    "print(f\"   ‚Ä¢ Model can predict placements with {results_df[results_df['Model'] == best_model_name_final]['Accuracy'].iloc[0]:.1%} accuracy\")\n",
    "\n",
    "print(f\"\\n‚úÖ Project Status: COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"üöÄ Ready for deployment and real-world application!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f79b0",
   "metadata": {},
   "source": [
    "## üí° Bonus: Streamlit Dashboard Code (Optional)\n",
    "\n",
    "Here's a bonus Streamlit app code that you can save and run for interactive predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5964e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Streamlit dashboard code\n",
    "streamlit_code = '''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"üéì College Placement Predictor\", \n",
    "    page_icon=\"üéØ\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Title and description\n",
    "st.title(\"üéì College Placement Prediction Dashboard\")\n",
    "st.markdown(\"### Predict student placement probability using machine learning!\")\n",
    "\n",
    "# Sidebar for input\n",
    "st.sidebar.header(\"üìù Student Information\")\n",
    "\n",
    "# Input fields\n",
    "cgpa = st.sidebar.slider(\"CGPA\", 0.0, 10.0, 7.5, 0.1)\n",
    "internships = st.sidebar.selectbox(\"Number of Internships\", [0, 1, 2, 3, 4])\n",
    "projects = st.sidebar.selectbox(\"Number of Projects\", [0, 1, 2, 3, 4, 5])\n",
    "certifications = st.sidebar.selectbox(\"Workshops/Certifications\", [0, 1, 2, 3, 4, 5])\n",
    "aptitude = st.sidebar.slider(\"Aptitude Test Score\", 0, 100, 75)\n",
    "soft_skills = st.sidebar.slider(\"Soft Skills Rating\", 0.0, 5.0, 4.0, 0.1)\n",
    "ssc_marks = st.sidebar.slider(\"SSC Marks\", 0, 100, 75)\n",
    "hsc_marks = st.sidebar.slider(\"HSC Marks\", 0, 100, 75)\n",
    "extracurricular = st.sidebar.selectbox(\"Extracurricular Activities\", [\"No\", \"Yes\"])\n",
    "placement_training = st.sidebar.selectbox(\"Placement Training\", [\"No\", \"Yes\"])\n",
    "\n",
    "# Create prediction button\n",
    "if st.sidebar.button(\"üéØ Predict Placement\", type=\"primary\"):\n",
    "    # Here you would load your trained model and make predictions\n",
    "    # For demonstration, we'll create a mock prediction\n",
    "    \n",
    "    # Calculate a simple score based on inputs\n",
    "    score = (cgpa/10 * 0.3 + \n",
    "             internships/4 * 0.2 + \n",
    "             certifications/5 * 0.2 + \n",
    "             aptitude/100 * 0.15 + \n",
    "             soft_skills/5 * 0.15)\n",
    "    \n",
    "    # Add bonuses for extracurricular and training\n",
    "    if extracurricular == \"Yes\":\n",
    "        score += 0.05\n",
    "    if placement_training == \"Yes\":\n",
    "        score += 0.05\n",
    "    \n",
    "    # Convert to probability\n",
    "    probability = min(score, 0.95)  # Cap at 95%\n",
    "    \n",
    "    # Display results\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    \n",
    "    with col1:\n",
    "        if probability > 0.7:\n",
    "            st.success(f\"üéâ HIGH CHANCE OF PLACEMENT\")\n",
    "            st.metric(\"Placement Probability\", f\"{probability:.1%}\")\n",
    "        elif probability > 0.4:\n",
    "            st.warning(f\"‚ö†Ô∏è MODERATE CHANCE\")\n",
    "            st.metric(\"Placement Probability\", f\"{probability:.1%}\")\n",
    "        else:\n",
    "            st.error(f\"‚ùå LOW CHANCE\")\n",
    "            st.metric(\"Placement Probability\", f\"{probability:.1%}\")\n",
    "    \n",
    "    with col2:\n",
    "        st.metric(\"Overall Score\", f\"{score:.2f}\")\n",
    "        st.metric(\"CGPA Impact\", f\"{cgpa/10*0.3:.2f}\")\n",
    "    \n",
    "    with col3:\n",
    "        st.metric(\"Experience Score\", f\"{(internships/4*0.2 + certifications/5*0.2):.2f}\")\n",
    "        st.metric(\"Skills Score\", f\"{(aptitude/100*0.15 + soft_skills/5*0.15):.2f}\")\n",
    "\n",
    "# Display student profile\n",
    "st.header(\"üìä Student Profile Summary\")\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    st.subheader(\"Academic Performance\")\n",
    "    st.write(f\"**CGPA:** {cgpa}/10\")\n",
    "    st.write(f\"**SSC Marks:** {ssc_marks}%\")\n",
    "    st.write(f\"**HSC Marks:** {hsc_marks}%\")\n",
    "    st.write(f\"**Aptitude Score:** {aptitude}/100\")\n",
    "\n",
    "with col2:\n",
    "    st.subheader(\"Experience & Skills\")\n",
    "    st.write(f\"**Internships:** {internships}\")\n",
    "    st.write(f\"**Projects:** {projects}\")\n",
    "    st.write(f\"**Certifications:** {certifications}\")\n",
    "    st.write(f\"**Soft Skills:** {soft_skills}/5\")\n",
    "    st.write(f\"**Extracurricular:** {extracurricular}\")\n",
    "    st.write(f\"**Placement Training:** {placement_training}\")\n",
    "\n",
    "# Recommendations\n",
    "st.header(\"üí° Improvement Recommendations\")\n",
    "recommendations = []\n",
    "\n",
    "if cgpa < 7.5:\n",
    "    recommendations.append(\"üìö Focus on improving CGPA (target: >7.5)\")\n",
    "if internships == 0:\n",
    "    recommendations.append(\"üíº Complete at least 1 internship\")\n",
    "if certifications < 2:\n",
    "    recommendations.append(\"üèÜ Earn more certifications (target: 2+)\")\n",
    "if aptitude < 75:\n",
    "    recommendations.append(\"üß† Improve aptitude test scores (target: >75)\")\n",
    "if soft_skills < 4.0:\n",
    "    recommendations.append(\"üó£Ô∏è Develop soft skills (target: >4.0)\")\n",
    "if extracurricular == \"No\":\n",
    "    recommendations.append(\"üèÉ‚Äç‚ôÇÔ∏è Participate in extracurricular activities\")\n",
    "if placement_training == \"No\":\n",
    "    recommendations.append(\"üéØ Enroll in placement training programs\")\n",
    "\n",
    "if recommendations:\n",
    "    for rec in recommendations:\n",
    "        st.write(f\"‚Ä¢ {rec}\")\n",
    "else:\n",
    "    st.success(\"üåü Excellent profile! Keep up the great work!\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"*Built with ‚ù§Ô∏è using Streamlit and Machine Learning*\")\n",
    "'''\n",
    "\n",
    "print(\"üíæ Streamlit Dashboard Code:\")\n",
    "print(\"=\"*50)\n",
    "print(\"Save the following code as 'placement_dashboard.py' and run with:\")\n",
    "print(\"streamlit run placement_dashboard.py\")\n",
    "print(\"\\n\" + streamlit_code)\n",
    "\n",
    "# Save the Streamlit code to a file\n",
    "with open('/home/parthnarkar/Desktop/DMBI-MiniProject/placement_dashboard.py', 'w') as f:\n",
    "    f.write(streamlit_code)\n",
    "\n",
    "print(\"‚úÖ Streamlit dashboard code saved as 'placement_dashboard.py'!\")\n",
    "print(\"üöÄ To run the dashboard: streamlit run placement_dashboard.py\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
